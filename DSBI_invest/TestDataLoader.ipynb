{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ovotools.params import AttrDict\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../NN/RetinaNet')\n",
    "import local_config\n",
    "from os.path import join\n",
    "model_name = 'NN_results/retina_points_cde773'\n",
    "model_fn = join(local_config.data_path, model_name)\n",
    "\n",
    "params = AttrDict.load(model_fn + '.param.txt', verbose = True)\n",
    "params.data.net_hw = (128,128,) #(512,768) ###### (1024,1536) #\n",
    "params.data.batch_size = 1 #######\n",
    "\n",
    "params.data.get_points = False\n",
    "#params.model_params.encoder_params.anchor_areas=[5 * 5., ] # 6 * 6., 10 * 10.,\n",
    "params.model_params.encoder_params.iuo_fit_thr = 0 # if iou > iuo_fit_thr => rect fits anchor\n",
    "params.model_params.encoder_params.iuo_nofit_thr = 0\n",
    "\n",
    "params.augmentation = AttrDict(\n",
    "    img_width_range=(1100, 1100),\n",
    "    stretch_limit = 0.1,\n",
    "    rotate_limit=5,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import ignite\n",
    "\n",
    "device = 'cuda:0'\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "import DSBI_invest.data\n",
    "import create_model_retinanet\n",
    "from data import int_to_label\n",
    "\n",
    "\n",
    "model, collate_fn, loss = create_model_retinanet.create_model_retinanet(params, phase='train', device=device)\n",
    "model = None\n",
    "\n",
    "train_loader, (val_loader1, val_loader2) = DSBI_invest.data.create_dataloaders(params, collate_fn,\n",
    "                                                                               mode = 'debug', verbose = 2)\n",
    "val_loader1_it = iter(val_loader1)\n",
    "\n",
    "import PIL\n",
    "import PIL.ImageDraw\n",
    "import PIL.ImageFont\n",
    "import numpy as np\n",
    "def TensorToPilImage(tensor, params):\n",
    "    std = (0.2,) #params.data.std\n",
    "    mean = (0.5,) #params.data.mean\n",
    "    vx_np = tensor.cpu().numpy().copy()\n",
    "    vx_np *= np.asarray(std)[:, np.newaxis, np.newaxis]\n",
    "    vx_np += np.asarray(mean)[:, np.newaxis, np.newaxis]\n",
    "    vx_np = vx_np.transpose(1,2,0)*255\n",
    "    return PIL.Image.fromarray(vx_np.astype(np.uint8))\n",
    "\n",
    "encoder = loss.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_loader1_it = iter(val_loader1)\n",
    "batch = next(val_loader1_it)\n",
    "data, target = ignite.engine._prepare_batch(batch, device=device)\n",
    "TensorToPilImage(data[0], params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_thresh = 0.6\n",
    "nms_thresh = 0.\n",
    "\n",
    "img = TensorToPilImage(data[0], params)\n",
    "w,h = img.size\n",
    "\n",
    "labels = target[1][0].clamp(min=0)\n",
    "ly = torch.eye(65, device = labels.device)  # [D,D]\n",
    "cls_preds = ly[labels][:,1:]\n",
    "\n",
    "boxest, labelst = encoder.decode(target[0][0].cpu().data, cls_preds, (w,h),\n",
    "                              cls_thresh = cls_thresh, nms_thresh = nms_thresh)\n",
    "print(len(boxest))\n",
    "import PIL.ImageFont\n",
    "draw = PIL.ImageDraw.Draw(img)\n",
    "fnt = PIL.ImageFont.truetype(\"arial.ttf\", 8)\n",
    "for i,box in enumerate(boxest):\n",
    "    draw.rectangle(list(box), outline='green')\n",
    "    draw.text((box[0],box[3]), int_to_label(labelst[i].item()), font=fnt, fill=(255,255,255,128))\n",
    "img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
