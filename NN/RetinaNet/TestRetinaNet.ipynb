{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверка работы нейросети для областей одинаковых товаров\n",
    "рисование картинок   \n",
    "вычисление symmetric_best_dice   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%aimport -sys, -os, -torch, -PIL, -PIL.ImageDraw, -PIL.ImageFont, -numpy as np\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Ïðîâåðêà ðàáîòû íåéðîñåòè äëÿ îáëàñòåé îäèíàêîâûõ òîâàðîâ\n",
    "# ðèñîâàíèå êàðòèíîê\n",
    "# âû÷èñëåíèå symmetric_best_dice\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "from ovotools.params import AttrDict\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "import local_config\n",
    "from os.path import join\n",
    "model_name = 'NN_results/retina_chars_72c04f'\n",
    "model_fn = join(local_config.data_path, model_name)\n",
    "\n",
    "params = AttrDict.load(model_fn + '.param.txt', verbose = True)\n",
    "model_fn += '/models/clr.017'\n",
    "params.data.net_hw = (1024,1024,) #(512,768) ###### (1024,1536) #\n",
    "params.data.batch_size = 1 #######\n",
    "\n",
    "params.model_params.encoder_params.iuo_fit_thr = 0 # if iou > iuo_fit_thr => rect fits anchor\n",
    "params.model_params.encoder_params.iuo_nofit_thr = 0\n",
    "\n",
    "params.augmentation = AttrDict(\n",
    "    img_width_range=(1024, 1024),\n",
    "    stretch_limit = 0.0,\n",
    "    rotate_limit=0,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import ignite\n",
    "\n",
    "device = 'cuda:0'\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "import DSBI_invest.data\n",
    "import create_model_retinanet\n",
    "import PIL\n",
    "import PIL.ImageDraw\n",
    "import PIL.ImageFont\n",
    "import numpy as np\n",
    "\n",
    "def TensorToPilImage(tensor, params):\n",
    "    std = (0.2,) #params.data.std\n",
    "    mean = (0.5,) #params.data.mean\n",
    "    vx_np = tensor.cpu().numpy().copy()\n",
    "    vx_np *= np.asarray(std)[:, np.newaxis, np.newaxis]\n",
    "    vx_np += np.asarray(mean)[:, np.newaxis, np.newaxis]\n",
    "    vx_np = vx_np.transpose(1,2,0)*255\n",
    "    return PIL.Image.fromarray(vx_np.astype(np.uint8))\n",
    "\n",
    "model, collate_fn, loss = create_model_retinanet.create_model_retinanet(params, phase='train', device=device)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load(model_fn))\n",
    "model.eval()\n",
    "print(\"Model loaded\")\n",
    "\n",
    "train_loader, (val_loader1, val_loader2) = DSBI_invest.data.create_dataloaders(params, collate_fn,\n",
    "                    data_dir=r'D:\\Programming\\Braille\\Data\\My', fn_suffix = '', mode='inference',\n",
    "                    verbose = 2)\n",
    "train_loader_it = None\n",
    "del train_loader_it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    batch = next(train_loader_it)\n",
    "except (StopIteration, NameError):\n",
    "    print('restarting epoch')\n",
    "    train_loader_it = iter(train_loader)\n",
    "    batch = next(train_loader_it)\n",
    "    \n",
    "data, target = ignite.engine._prepare_batch(batch, device=device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    (loc_preds, cls_preds) = model(data.to(device))\n",
    "loss_val = loss((loc_preds, cls_preds), target)\n",
    "loss_val, loss.get_dict()\n",
    "\n",
    "img = TensorToPilImage(data[0], params)\n",
    "w,h = img.size\n",
    "\n",
    "cls_thresh = 0.3\n",
    "nms_thresh = 0\n",
    "\n",
    "encoder = loss.encoder\n",
    "boxes, labels, scores = encoder.decode(loc_preds[0].cpu().data, cls_preds[0].cpu().data, (w,h),\n",
    "                              cls_thresh = cls_thresh, nms_thresh = nms_thresh)\n",
    "\n",
    "draw = PIL.ImageDraw.Draw(img)\n",
    "fnt = PIL.ImageFont.truetype(\"arial.ttf\", 8)\n",
    "fntA = PIL.ImageFont.truetype(\"arial.ttf\", 12)\n",
    "for i, box in enumerate(boxes):\n",
    "    draw.rectangle(list(box), outline='green')\n",
    "    int_lbl = labels[i].item()\n",
    "    lbl = DSBI_invest.data.int_to_letter(int_lbl, 'RU')\n",
    "    #lbl = '' #GVNC\n",
    "    if not lbl:\n",
    "        lbl = DSBI_invest.data.int_to_label(int_lbl)\n",
    "        lbl = lbl[:3]+'.'+lbl[3:]\n",
    "    score = scores[i].item()\n",
    "    score = '{:.1f}'.format(score*10)\n",
    "    draw.text((box[0],box[3]), lbl, font=fntA, fill=\"white\")\n",
    "    draw.text((box[0],box[3]+12), score, font=fnt, fill='green')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_thresh = 0.3\n",
    "nms_thresh = 0\n",
    "\n",
    "encoder = loss.encoder\n",
    "boxes, labels = encoder.decode(loc_preds[0].cpu().data, cls_preds[0].cpu().data, (w,h),\n",
    "                              cls_thresh = cls_thresh, nms_thresh = nms_thresh)\n",
    "\n",
    "print\n",
    "img = TensorToPilImage(data[0], params)\n",
    "draw = PIL.ImageDraw.Draw(img)\n",
    "for box in boxes:\n",
    "    draw.rectangle(list(box), outline='red')\n",
    "img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_preds[0].cpu().data.shape, cls_preds[0].shape, \\\n",
    "loc_preds[0].cpu().data.min(), cls_preds[0].min(), \\\n",
    "loc_preds[0].cpu().data.max(), cls_preds[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target[1][0].unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.iuo_fit_thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxest, labelst, _ = encoder.decode(target[0][0].cpu().data, target[1][0].cpu().clamp(0,1).unsqueeze(1).float().data, (w,h),\n",
    "                              cls_thresh = 0, nms_thresh = 0)\n",
    "\n",
    "draw = PIL.ImageDraw.Draw(img)\n",
    "for box in boxest:\n",
    "    draw.rectangle(list(box), outline='green')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
